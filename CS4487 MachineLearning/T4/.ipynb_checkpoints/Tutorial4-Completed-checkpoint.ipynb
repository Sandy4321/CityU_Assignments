{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Tutorial 4: Predicting Popularity of Online News\n",
    "\n",
    "In this tutorial you will train regression models to predict the number of \"shares\" of a news article on Mashable.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import string\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data and Pre-processing\n",
    "Next we need to load the data.  Download `OnlineNewsPopularity.zip`, and **unzip** it in the same directory as this ipynb file.  Then run the following cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'OnlineNewsPopularity/OnlineNewsPopularity.csv'\n",
    "\n",
    "# read the data\n",
    "allfeatnames = []\n",
    "textdata      = []\n",
    "with open(filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if len(allfeatnames)==0:\n",
    "            allfeatnames = row\n",
    "        else:\n",
    "            textdata.append(row)\n",
    "\n",
    "# put the data into a np array\n",
    "dataX = empty((len(textdata), len(allfeatnames)-3))\n",
    "dataY = empty(len(textdata))\n",
    "for i,row in enumerate(textdata):\n",
    "    # extract features (remove the first 2 features and the last feature)\n",
    "    dataX[i,:] = array([float(x) for x in row[2:-1]])\n",
    "    # extract target (last entry)\n",
    "    dataY[i] = float(row[-1])\n",
    "    \n",
    "# extract feature names\n",
    "featnames = [x.strip() for x in allfeatnames[2:-1]]\n",
    "\n",
    "# extract a subset of data\n",
    "dataX = dataX[::6]\n",
    "dataY = dataY[::6]\n",
    "\n",
    "print(dataX.shape)\n",
    "print(dataY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 58 features for each article.  Here are the feature names, and an example entry.  The actual description of the features can be found in the `OnlineNewsPopularity-features.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featnames)\n",
    "\n",
    "print(\"--- example article features---\")\n",
    "print(dataX[0])\n",
    "print(\"--- example article target (# of shares)\")\n",
    "print(dataY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now separate the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into 50% train and 50% test set\n",
    "trainX, testX, trainYo, testYo = \\\n",
    "  model_selection.train_test_split(dataX, dataY, \n",
    "  train_size=0.50, test_size=0.50, random_state=4487)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we normalize the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize feature values\n",
    "# this makes comparing weights more meaningful\n",
    "scaler = preprocessing.StandardScaler()  \n",
    "trainXn = scaler.fit_transform(trainX)  \n",
    "testXn  = scaler.transform(testX)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the target value (number of shares) has a large dynamic range, we will transform the target values through the log function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map targets to log-space\n",
    "trainY = log10(trainYo)\n",
    "testY  = log10(testYo)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(trainYo, 25);\n",
    "plt.title('histogram of Y values')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(trainY, 25);\n",
    "plt.title(\"histogram of log(Y) values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction with Linear Regression\n",
    "\n",
    "First we will look at predicting the number of shares using simple linear regression models.  Use the training data to fit a linear model using Ordinary Least Squares and Ridge Regression.  Use cross-validation on the training set to select the optimal $\\alpha$ parameter for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT: \n",
    "# 1. Ordinary Least Squares: linear_model.LinearRegression()\n",
    "# 2. Ridge Regression: linear_model.Ridge(alphas= )\n",
    "# 3. Rigge Regression with Cross-validation: linear_model.Ridge(alphas= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two models using the _average absolute error_ (AE) between the predictions and the true values.  Below is  code that will calculate AE for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols is the linear regression model\n",
    "trainAE = metrics.mean_absolute_error(trainY, ols.predict(trainXn))\n",
    "testAE  = metrics.mean_absolute_error(testY, ols.predict(testXn))\n",
    "print(\"OLS: train error =\", trainAE)\n",
    "print(\"OLS: test error =\", testAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr is the ridge regression model\n",
    "trainAE = metrics.mean_absolute_error(trainY, rr.predict(trainXn))\n",
    "testAE  = metrics.mean_absolute_error(testY, rr.predict(testXn))\n",
    "print(\"RR: train error =\", trainAE)\n",
    "print(\"RR: test error =\", testAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model has better prediction ability on the test set? Why?\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Which features are important?\n",
    "Next we will investigate which features are the most important for the prediction.  Use LASSO with cross-validation to learn the model, and print the training and testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT\n",
    "# 1. LASSO with Cross-validation: linear_model.LassoCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the LASSO coefficients by sorting them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort coefficients from smallest to largest, then reverse it\n",
    "inds = argsort(abs(las.coef_))[::-1]\n",
    "# print out\n",
    "print(\"weight : feature description\")\n",
    "for i in inds:\n",
    "    print(\"{: .3f} : {}\".format(las.coef_[i], featnames[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which features are most important for predicting the number of shares?  For these features, which feature values (low or high values) will yield a higher number of shares?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
