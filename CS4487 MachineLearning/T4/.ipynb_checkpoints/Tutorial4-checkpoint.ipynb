{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** LOW, Zhi Hao\n",
    "\n",
    "**EID:** zhlow2\n",
    "\n",
    "**SID:** 54924670"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Tutorial 4: Predicting Popularity of Online News\n",
    "\n",
    "In this tutorial you will train regression models to predict the number of \"shares\" of a news article on Mashable.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import string\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data and Pre-processing\n",
    "Next we need to load the data.  Download `OnlineNewsPopularity.zip`, and **unzip** it in the same directory as this ipynb file.  Then run the following cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6608, 58)\n",
      "(6608,)\n"
     ]
    }
   ],
   "source": [
    "filename = 'OnlineNewsPopularity/OnlineNewsPopularity.csv'\n",
    "\n",
    "# read the data\n",
    "allfeatnames = []\n",
    "textdata      = []\n",
    "with open(filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if len(allfeatnames)==0:\n",
    "            allfeatnames = row\n",
    "        else:\n",
    "            textdata.append(row)\n",
    "\n",
    "# put the data into a np array\n",
    "dataX = empty((len(textdata), len(allfeatnames)-3))\n",
    "dataY = empty(len(textdata))\n",
    "for i,row in enumerate(textdata):\n",
    "    # extract features (remove the first 2 features and the last feature)\n",
    "    dataX[i,:] = array([float(x) for x in row[2:-1]])\n",
    "    # extract target (last entry)\n",
    "    dataY[i] = float(row[-1])\n",
    "    \n",
    "# extract feature names\n",
    "featnames = [x.strip() for x in allfeatnames[2:-1]]\n",
    "\n",
    "# extract a subset of data\n",
    "dataX = dataX[::6]\n",
    "dataY = dataY[::6]\n",
    "\n",
    "print(dataX.shape)\n",
    "print(dataY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 58 features for each article.  Here are the feature names, and an example entry.  The actual description of the features can be found in the `OnlineNewsPopularity-features.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_tokens_title', 'n_tokens_content', 'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length', 'num_keywords', 'data_channel_is_lifestyle', 'data_channel_is_entertainment', 'data_channel_is_bus', 'data_channel_is_socmed', 'data_channel_is_tech', 'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min', 'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity', 'global_sentiment_polarity', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity', 'max_positive_polarity', 'avg_negative_polarity', 'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity', 'title_sentiment_polarity', 'abs_title_subjectivity', 'abs_title_sentiment_polarity']\n",
      "--- example article features---\n",
      "[ 1.20000000e+01  2.19000000e+02  6.63594467e-01  9.99999992e-01\n",
      "  8.15384609e-01  4.00000000e+00  2.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  4.68036530e+00  5.00000000e+00  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  4.96000000e+02  4.96000000e+02\n",
      "  4.96000000e+02  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  5.00331204e-01  3.78278930e-01  4.00046751e-02\n",
      "  4.12626477e-02  4.01225435e-02  5.21617145e-01  9.25619835e-02\n",
      "  4.56621005e-02  1.36986301e-02  7.69230769e-01  2.30769231e-01\n",
      "  3.78636364e-01  1.00000000e-01  7.00000000e-01 -3.50000000e-01\n",
      " -6.00000000e-01 -2.00000000e-01  5.00000000e-01 -1.87500000e-01\n",
      "  0.00000000e+00  1.87500000e-01]\n",
      "--- example article target (# of shares)\n",
      "593.0\n"
     ]
    }
   ],
   "source": [
    "print(featnames)\n",
    "\n",
    "print(\"--- example article features---\")\n",
    "print(dataX[0])\n",
    "print(\"--- example article target (# of shares)\")\n",
    "print(dataY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now separate the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3304, 58)\n",
      "(3304, 58)\n"
     ]
    }
   ],
   "source": [
    "# randomly split data into 50% train and 50% test set\n",
    "trainX, testX, trainYo, testYo = \\\n",
    "  model_selection.train_test_split(dataX, dataY, \n",
    "  train_size=0.50, test_size=0.50, random_state=4487)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we normalize the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize feature values\n",
    "# this makes comparing weights more meaningful\n",
    "scaler = preprocessing.StandardScaler()  \n",
    "trainXn = scaler.fit_transform(trainX)  \n",
    "testXn  = scaler.transform(testX)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the target value (number of shares) has a large dynamic range, we will transform the target values through the log function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map targets to log-space\n",
    "trainY = log10(trainYo)\n",
    "testY  = log10(testYo)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(trainYo, 25);\n",
    "plt.title('histogram of Y values')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(trainY, 25);\n",
    "plt.title(\"histogram of log(Y) values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction with Linear Regression\n",
    "\n",
    "First we will look at predicting the number of shares using simple linear regression models.  Use the training data to fit a linear model using Ordinary Least Squares and Ridge Regression.  Use cross-validation on the training set to select the optimal $\\alpha$ parameter for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT: \n",
    "# 1. Ordinary Least Squares: linear_model.LinearRegression()\n",
    "# 2. Ridge Regression: linear_model.Ridge(alphas= )\n",
    "# 3. Rigge Regression with Cross-validation: linear_model.Ridge(alphas= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two models using the _average absolute error_ (AE) between the predictions and the true values.  Below is  code that will calculate AE for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols is the linear regression model\n",
    "trainAE = metrics.mean_absolute_error(trainY, ols.predict(trainXn))\n",
    "testAE  = metrics.mean_absolute_error(testY, ols.predict(testXn))\n",
    "print(\"OLS: train error =\", trainAE)\n",
    "print(\"OLS: test error =\", testAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr is the ridge regression model\n",
    "trainAE = metrics.mean_absolute_error(trainY, rr.predict(trainXn))\n",
    "testAE  = metrics.mean_absolute_error(testY, rr.predict(testXn))\n",
    "print(\"RR: train error =\", trainAE)\n",
    "print(\"RR: test error =\", testAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model has better prediction ability on the test set? Why?\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Which features are important?\n",
    "Next we will investigate which features are the most important for the prediction.  Use LASSO with cross-validation to learn the model, and print the training and testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT\n",
    "# 1. LASSO with Cross-validation: linear_model.LassoCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the LASSO coefficients by sorting them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort coefficients from smallest to largest, then reverse it\n",
    "inds = argsort(abs(las.coef_))[::-1]\n",
    "# print out\n",
    "print(\"weight : feature description\")\n",
    "for i in inds:\n",
    "    print(\"{: .3f} : {}\".format(las.coef_[i], featnames[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which features are most important for predicting the number of shares?  For these features, which feature values (low or high values) will yield a higher number of shares?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
