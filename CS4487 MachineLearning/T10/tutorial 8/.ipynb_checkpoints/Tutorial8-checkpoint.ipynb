{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Tutorial 8\n",
    "## Non-Linear Dimensionality Reduction and Face Recognition\n",
    "\n",
    "In this tutorial you will use non-linear dimensionality reduction on face images, and then train a classifier for face recognition.  You will then use manifold embedding to visualize the data.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "random.seed(100)\n",
    "rbow = plt.get_cmap('rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Pre-processing\n",
    "We first need to load the images.  We will use the same dataset as Tutorial 7. Download `olivetti_py3.pkz` from Canvas, and place it in in the same directory as this ipynb file.  _DO NOT UNZIP IT_.  Then run the following cell to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oli = datasets.fetch_olivetti_faces(data_home=\"./\")\n",
    "X = oli.data\n",
    "Y = oli.target\n",
    "img = oli.images\n",
    "imgsize = oli.images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 64x64 array of pixel values, resulting in a 4096 dimensional vector.  Run the below code to show all the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(0,400,20):\n",
    "    tmp.append( hstack(img[i:i+20]) )\n",
    "allimg = vstack(tmp)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(allimg, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each person is considered as one class, and there are 10 images for each class.  In total there are 40 classes (people).  The data is already vectorized and put into the matrix `X`. Now we split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into 80% train and 20% test set\n",
    "trainX, testX, trainY, testY = \\\n",
    "  model_selection.train_test_split(X, Y, \n",
    "  train_size=0.80, test_size=0.20, random_state=4487)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear Dimensionality Reduction - KPCA\n",
    "The dimension of the data is too large (4096) so learning classifiers will take a long time.  Instead, our strategy is to use KPCA to reduce the dimension first and then use the KPCA weights as the representation for each image.  Run KPCA on the data using 10 principal components.  Use the RBF kernel with gamma=0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will plot the basis vectors of KPCA. Run the next 2 cells to view the PCs.  The kernel PCs are a combination of similarities to points in the training set.  The PCs are visualized by showing the top 5 positive and negative training examples, along with their coefficient $\\alpha_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kbasis(model, imgsize, X):\n",
    "    KK = model.n_components\n",
    "    alphas = model.alphas_.T\n",
    "    minmax = 5\n",
    "    \n",
    "    py = KK\n",
    "    px = minmax*2\n",
    "    for i in range(KK):\n",
    "        # sort alphas\n",
    "        inds = argsort(alphas[i,:])\n",
    "\n",
    "        myi = r_[arange(-1,-minmax-1,-1), arange(minmax-1,-1,-1)]\n",
    "        myinds = inds[myi]\n",
    "        \n",
    "        for j,jj in enumerate(myinds):\n",
    "            plt.subplot(py,px,(j+1)+i*px)\n",
    "            plt.imshow(X[jj,:].reshape(imgsize), interpolation='nearest')\n",
    "            plt.gray()\n",
    "            if alphas[i,jj]<0:\n",
    "                mycol = 'b'\n",
    "            else:\n",
    "                mycol = 'r'\n",
    "            plt.title(\"{:.3f}\".format(alphas[i,jj]), fontsize=7, color=mycol)\n",
    "            if (j==0):\n",
    "                plt.ylabel('PC' + str(i+1))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function\n",
    "plt.figure(figsize=(10,12))\n",
    "plot_kbasis(kpca, imgsize, trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What is the interpretation for the KPCA basis?  What kind of faces do some of the PCs prefer?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition\n",
    "Now train a _linear_ classifier to do the face recognition.  Use the calculated KPCA representation as the new set of inputs.  Use cross-validation to set the hyperparameters of the classifier.  You do not need to do cross-validation for the number of components or kernel hyperparameters.  Calculate the average training and testing accuracies.  Remember to transform the test data into the KPCA representation too!\n",
    "\n",
    "**NOTE**: It is **NOT** recommended to use `svm.SVC` for the training.  This is because the default SVC implements 1-vs-1 multi-class classification, which means it will calculate 40x39=1560 classifiers!  All other classifier should be fine since they do 1-vs-all multi-class classification, e.g., LogisticRegressionCV, LinearSVC, etc.  If you want to use svm.SVC, make sure to use the OneVsRestClassifier as shown in Lecture 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best kernel and best number of components\n",
    "Now try different kernels (poly, RBF, etc), kernel parameters, and number of components to get the best test accuracy.  Train a classifier for each one and see which dimension gives the best testing accuracy.  Make a plots of number of components vs. test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What is the best kernel and number of components?  View the prototypes for each compenent to see what they look like_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Manifold embedding\n",
    "Now you will use manifold embedding to visualize the dataset.\n",
    "Use various methods to embed the data into 2 dimensions.  Use the below function to plot the low-dimensional data. **Note:** use the whole dataset `X` to do the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(X, Y, title=None):\n",
    "    # X is the low-dim data\n",
    "    zoomfact = 0.25  # change this to make images bigger/smaller\n",
    "    \n",
    "    x_min, x_max = amin(X, 0), amax(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], c=Y, cmap=rbow, edgecolor=\"\")\n",
    "    \n",
    "    if hasattr(matplotlib.offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = array([[1., 1.]])  # just something big\n",
    "        for i in range(img.shape[0]):\n",
    "            dist = sum((X[i] - shown_images) ** 2, 1)\n",
    "            if min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = r_[shown_images, [X[i]]]\n",
    "            imagebox = matplotlib.offsetbox.AnnotationBbox(\n",
    "                matplotlib.offsetbox.OffsetImage(img[i], \n",
    "                    zoom=zoomfact, \n",
    "                    cmap=plt.cm.gray), X[i], pad=0.02)\n",
    "            imagebox.patch.set_edgecolor(rbow(Y[i]/max(Y)))\n",
    "            imagebox.patch.set_linewidth(2)\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which embedding looks the best in terms of preserving structure of the data (similarity between images)?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
