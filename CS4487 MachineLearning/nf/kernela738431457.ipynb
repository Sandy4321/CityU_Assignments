{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12897385383966420613\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9215183422\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12818675078665686471\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization,Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file, train=True):\n",
    "    import pickle\n",
    "    with open('./cifar10-python/cifar-10-batches-py/'+(('data_batch_'+str(file)) if train else 'test_batch'), 'rb') as fo:\n",
    "        dict_d = pickle.load(fo, encoding='latin1')\n",
    "    return np.reshape(dict_d['data'],(10000,3,32,32)).transpose(0, 2, 3, 1), dict_d['labels']\n",
    "def normalization(x):\n",
    "    return x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "training_label = []\n",
    "for i in range(1,6):\n",
    "    x,y = unpickle(i)\n",
    "    training_set.extend(x) \n",
    "    training_label.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data,test_label = unpickle(0,train=False)\n",
    "test_data_norm = normalization(np.array(test_data))\n",
    "test_label_one_hot_encoded = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_norm = np.array(training_set) / 255\n",
    "training_label_one_hot_encode = to_categorical(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.extend(test_data)\n",
    "training_label_one_hot_encode = np.concatenate((training_label_one_hot_encode,test_label_one_hot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_norm = np.array(training_set) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label_one_hot_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "datagen.fit(training_set_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name = [\n",
    "\"airplane\",\n",
    "\"automobile\",\n",
    "\"bird\",\n",
    "\"cat\",\n",
    "\"deer\",\n",
    "\"dog\",\n",
    "\"frog\",\n",
    "\"horse\",\n",
    "\"ship\",\n",
    "\"truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [0]*10\n",
    "for i in training_label:\n",
    "    counts[i] += 1\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr,lab):\n",
    "    from matplotlib import pyplot as plt\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    for i in lab[:5]:\n",
    "        print(labels_name[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog truck truck deer automobile "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile bird horse ship cat "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deer horse horse bird truck "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck truck cat bird frog "
     ]
    }
   ],
   "source": [
    "for i in range(0,20,5):\n",
    "    plotImages(training_set_norm[i:i+5],training_label[i:i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Data reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 2.0276 - acc: 0.2220A: 0s - loss: 2.0402 - ac\n",
      "Epoch 2/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.6642 - acc: 0.3953\n",
      "Epoch 3/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.4896 - acc: 0.4700\n",
      "Epoch 4/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.3752 - acc: 0.5288\n",
      "Epoch 5/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.3227 - acc: 0.5485\n",
      "Epoch 6/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.3037 - acc: 0.5576\n",
      "Epoch 7/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.2132 - acc: 0.5937\n",
      "Epoch 8/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.2462 - acc: 0.5900\n",
      "Epoch 9/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.2555 - acc: 0.5874\n",
      "Epoch 10/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.2914 - acc: 0.5780\n",
      "Epoch 11/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.2965 - acc: 0.5687\n",
      "Epoch 12/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0836 - acc: 0.6413\n",
      "Epoch 13/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0515 - acc: 0.6555\n",
      "Epoch 14/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0365 - acc: 0.6600\n",
      "Epoch 15/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0429 - acc: 0.6610\n",
      "Epoch 16/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0425 - acc: 0.6567\n",
      "Epoch 17/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0483 - acc: 0.6568\n",
      "Epoch 18/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0543 - acc: 0.6570\n",
      "Epoch 19/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0598 - acc: 0.6581\n",
      "Epoch 20/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0621 - acc: 0.6573\n",
      "Epoch 21/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0600 - acc: 0.6576\n",
      "Epoch 22/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0645 - acc: 0.6572\n",
      "Epoch 23/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0735 - acc: 0.6517\n",
      "Epoch 24/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0708 - acc: 0.6529\n",
      "Epoch 25/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0670 - acc: 0.6541\n",
      "Epoch 26/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0665 - acc: 0.6553\n",
      "Epoch 27/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0757 - acc: 0.6530\n",
      "Epoch 28/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0657 - acc: 0.6540\n",
      "Epoch 29/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0627 - acc: 0.6569\n",
      "Epoch 30/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0670 - acc: 0.6575\n",
      "Epoch 31/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0706 - acc: 0.6561\n",
      "Epoch 32/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0519 - acc: 0.6572\n",
      "Epoch 33/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0637 - acc: 0.6578\n",
      "Epoch 34/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0758 - acc: 0.6542\n",
      "Epoch 35/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.0661 - acc: 0.6548\n",
      "Epoch 36/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0576 - acc: 0.6573\n",
      "Epoch 37/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0711 - acc: 0.6540\n",
      "Epoch 38/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0633 - acc: 0.6542\n",
      "Epoch 39/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0760 - acc: 0.6542\n",
      "Epoch 40/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0616 - acc: 0.6568\n",
      "Epoch 41/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0505 - acc: 0.6578\n",
      "Epoch 42/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0749 - acc: 0.6547\n",
      "Epoch 43/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0704 - acc: 0.6535\n",
      "Epoch 44/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0625 - acc: 0.6529\n",
      "Epoch 45/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0496 - acc: 0.6591\n",
      "Epoch 46/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0568 - acc: 0.6583\n",
      "Epoch 47/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0519 - acc: 0.6605\n",
      "Epoch 48/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0578 - acc: 0.6586\n",
      "Epoch 49/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0584 - acc: 0.6599\n",
      "Epoch 50/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0696 - acc: 0.6563\n",
      "Epoch 51/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0620 - acc: 0.6548\n",
      "Epoch 52/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0571 - acc: 0.6581\n",
      "Epoch 53/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0626 - acc: 0.6564\n",
      "Epoch 54/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0701 - acc: 0.6598\n",
      "Epoch 55/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0538 - acc: 0.6597\n",
      "Epoch 56/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0752 - acc: 0.6580\n",
      "Epoch 57/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0558 - acc: 0.6584\n",
      "Epoch 58/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0761 - acc: 0.6555\n",
      "Epoch 59/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0573 - acc: 0.6570\n",
      "Epoch 60/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0616 - acc: 0.6537\n",
      "Epoch 61/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0725 - acc: 0.6567\n",
      "Epoch 62/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0679 - acc: 0.6582\n",
      "Epoch 63/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0697 - acc: 0.6571\n",
      "Epoch 64/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0551 - acc: 0.6608\n",
      "Epoch 65/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0655 - acc: 0.6576\n",
      "Epoch 66/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0585 - acc: 0.6619\n",
      "Epoch 67/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0616 - acc: 0.6601\n",
      "Epoch 68/170\n",
      "545/937 [================>.............] - ETA: 3s - loss: 1.0737 - acc: 0.6537"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-da3cf9fb9961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m170\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    102\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_label_one_hot_encoded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[1;32m--> 176\u001b[1;33m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1940\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = Sequential([\n",
    "#     Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "#     MaxPooling2D((2,2),padding='same'),\n",
    "#     Dropout(0.2),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# train test merge:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=training_set_norm.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "datagen.fit(training_set_norm)\n",
    "\n",
    "model.compile(optimizer= opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 5:\n",
    "        lrate = 0.0007\n",
    "    if epoch > 10:\n",
    "        lrate = 0.00005\n",
    "    if epoch > 25:\n",
    "        lrate = 0.0000001\n",
    "    if epoch > 50:\n",
    "        lrate = 0.00000005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.00000001\n",
    "    if epoch > 150:\n",
    "        lrate = 0.000000005\n",
    "    return lrate\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\n",
    "    steps_per_epoch=len(training_set_norm) / 16, \n",
    "    epochs=170,\n",
    "    workers=8,\n",
    "    callbacks=[LearningRateScheduler(lr_schedule)]\n",
    ")\n",
    "accuracy = model.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0606 - acc: 0.6590\n",
      "Epoch 70/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0595 - acc: 0.6594: 0s - loss: 1.0597 - \n",
      "Epoch 71/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0579 - acc: 0.6585\n",
      "Epoch 72/170\n",
      "3750/3750 [==============================] - 29s 8ms/step - loss: 1.0561 - acc: 0.6581\n",
      "Epoch 73/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0606 - acc: 0.6602\n",
      "Epoch 74/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0577 - acc: 0.6592\n",
      "Epoch 75/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0622 - acc: 0.6573\n",
      "Epoch 76/170\n",
      "2739/3750 [====================>.........] - ETA: 7s - loss: 1.0603 - acc: 0.6586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7d6a5480169a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m68\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_label_one_hot_encoded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[1;32m--> 176\u001b[1;33m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1940\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model1 = load_model('./model.h5')\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 5:\n",
    "        lrate = 0.0007\n",
    "    if epoch > 10:\n",
    "        lrate = 0.00005\n",
    "    if epoch > 25:\n",
    "        lrate = 0.0000001\n",
    "    if epoch > 50:\n",
    "        lrate = 0.000000005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.000000001\n",
    "    if epoch > 150:\n",
    "        lrate = 0.0000000005\n",
    "    return lrate\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\n",
    "    steps_per_epoch=len(training_set_norm) / 16, \n",
    "    epochs=170,\n",
    "    workers=4,\n",
    "    callbacks=[LearningRateScheduler(lr_schedule)],\n",
    "    initial_epoch=68\n",
    ")\n",
    "accuracy = model.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 1.7437 - acc: 0.4580 - val_loss: 1.3825 - val_acc: 0.5715\n",
      "Epoch 2/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.1420 - acc: 0.6367 - val_loss: 1.1330 - val_acc: 0.6543\n",
      "Epoch 3/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.9793 - acc: 0.6946 - val_loss: 0.8791 - val_acc: 0.7399\n",
      "Epoch 4/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.8939 - acc: 0.7292 - val_loss: 0.9167 - val_acc: 0.7337\n",
      "Epoch 5/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.8410 - acc: 0.7523 - val_loss: 0.7745 - val_acc: 0.7828\n",
      "Epoch 6/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.8094 - acc: 0.7668 - val_loss: 0.6729 - val_acc: 0.8125\n",
      "Epoch 7/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7859 - acc: 0.7776 - val_loss: 0.8040 - val_acc: 0.7823\n",
      "Epoch 8/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7701 - acc: 0.7840 - val_loss: 0.7042 - val_acc: 0.8138\n",
      "Epoch 9/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7532 - acc: 0.7919 - val_loss: 0.6238 - val_acc: 0.8386\n",
      "Epoch 10/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7416 - acc: 0.7964 - val_loss: 0.7051 - val_acc: 0.8156\n",
      "Epoch 11/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7290 - acc: 0.8013 - val_loss: 0.6668 - val_acc: 0.8285\n",
      "Epoch 12/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7243 - acc: 0.8059 - val_loss: 0.6794 - val_acc: 0.8227\n",
      "Epoch 13/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7141 - acc: 0.8090 - val_loss: 0.7849 - val_acc: 0.7933\n",
      "Epoch 14/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7074 - acc: 0.8115 - val_loss: 0.6278 - val_acc: 0.8457\n",
      "Epoch 15/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7025 - acc: 0.8141 - val_loss: 0.6199 - val_acc: 0.8465\n",
      "Epoch 16/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6989 - acc: 0.8173 - val_loss: 0.6530 - val_acc: 0.8393\n",
      "Epoch 17/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6940 - acc: 0.8172 - val_loss: 0.6481 - val_acc: 0.8388\n",
      "Epoch 18/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6895 - acc: 0.8218 - val_loss: 0.5903 - val_acc: 0.8566\n",
      "Epoch 19/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6819 - acc: 0.8244 - val_loss: 0.6832 - val_acc: 0.8291\n",
      "Epoch 20/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6782 - acc: 0.8254 - val_loss: 0.5548 - val_acc: 0.8690\n",
      "Epoch 21/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6777 - acc: 0.8261 - val_loss: 0.6352 - val_acc: 0.8518\n",
      "Epoch 22/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6705 - acc: 0.8279 - val_loss: 0.5915 - val_acc: 0.8585\n",
      "Epoch 23/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6701 - acc: 0.8288 - val_loss: 0.6598 - val_acc: 0.8422\n",
      "Epoch 24/125\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.6657 - acc: 0.8301 - val_loss: 0.5701 - val_acc: 0.8691\n",
      "Epoch 25/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6624 - acc: 0.8330 - val_loss: 0.5925 - val_acc: 0.8588\n",
      "Epoch 26/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6637 - acc: 0.8325 - val_loss: 0.5807 - val_acc: 0.8640\n",
      "Epoch 27/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6558 - acc: 0.8346 - val_loss: 0.5978 - val_acc: 0.8542\n",
      "Epoch 28/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6571 - acc: 0.8352 - val_loss: 0.5378 - val_acc: 0.8751\n",
      "Epoch 29/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6555 - acc: 0.8348 - val_loss: 0.5423 - val_acc: 0.8738\n",
      "Epoch 30/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6561 - acc: 0.8334 - val_loss: 0.5968 - val_acc: 0.8608\n",
      "Epoch 31/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6535 - acc: 0.8373 - val_loss: 0.5835 - val_acc: 0.8598\n",
      "Epoch 32/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6492 - acc: 0.8380 - val_loss: 0.5793 - val_acc: 0.8616\n",
      "Epoch 33/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6478 - acc: 0.8375 - val_loss: 0.5425 - val_acc: 0.8737\n",
      "Epoch 34/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6416 - acc: 0.8407 - val_loss: 0.6014 - val_acc: 0.8580\n",
      "Epoch 35/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6433 - acc: 0.8405 - val_loss: 0.5882 - val_acc: 0.8598\n",
      "Epoch 36/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6399 - acc: 0.8410 - val_loss: 0.5784 - val_acc: 0.8640\n",
      "Epoch 37/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6412 - acc: 0.8410 - val_loss: 0.6685 - val_acc: 0.8371\n",
      "Epoch 38/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6423 - acc: 0.8411 - val_loss: 0.6253 - val_acc: 0.8544\n",
      "Epoch 39/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6341 - acc: 0.8429 - val_loss: 0.5239 - val_acc: 0.8817\n",
      "Epoch 40/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6369 - acc: 0.8413 - val_loss: 0.5219 - val_acc: 0.8811\n",
      "Epoch 41/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6345 - acc: 0.8431 - val_loss: 0.5522 - val_acc: 0.8725\n",
      "Epoch 42/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6369 - acc: 0.8437 - val_loss: 0.6084 - val_acc: 0.8511\n",
      "Epoch 43/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6332 - acc: 0.8441 - val_loss: 0.5428 - val_acc: 0.8740\n",
      "Epoch 44/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6310 - acc: 0.8456 - val_loss: 0.5621 - val_acc: 0.8669\n",
      "Epoch 45/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6307 - acc: 0.8459 - val_loss: 0.6157 - val_acc: 0.8593\n",
      "Epoch 46/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6263 - acc: 0.8466 - val_loss: 0.5216 - val_acc: 0.8832\n",
      "Epoch 47/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6263 - acc: 0.8467 - val_loss: 0.5924 - val_acc: 0.8585\n",
      "Epoch 48/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6266 - acc: 0.8474 - val_loss: 0.5575 - val_acc: 0.8706\n",
      "Epoch 49/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6276 - acc: 0.8464 - val_loss: 0.5328 - val_acc: 0.8785\n",
      "Epoch 50/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6212 - acc: 0.8478 - val_loss: 0.5839 - val_acc: 0.8659\n",
      "Epoch 51/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6254 - acc: 0.8479 - val_loss: 0.5540 - val_acc: 0.8730\n",
      "Epoch 52/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6218 - acc: 0.8487 - val_loss: 0.5164 - val_acc: 0.8847\n",
      "Epoch 53/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6204 - acc: 0.8479 - val_loss: 0.5708 - val_acc: 0.8672\n",
      "Epoch 54/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6166 - acc: 0.8499 - val_loss: 0.5277 - val_acc: 0.8794\n",
      "Epoch 55/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6181 - acc: 0.8495 - val_loss: 0.5175 - val_acc: 0.8864\n",
      "Epoch 56/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6194 - acc: 0.8501 - val_loss: 0.5089 - val_acc: 0.8881\n",
      "Epoch 57/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6159 - acc: 0.8513 - val_loss: 0.5230 - val_acc: 0.8816\n",
      "Epoch 58/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6187 - acc: 0.8485 - val_loss: 0.5611 - val_acc: 0.8681\n",
      "Epoch 59/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6180 - acc: 0.8486 - val_loss: 0.5475 - val_acc: 0.8759\n",
      "Epoch 60/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6138 - acc: 0.8514 - val_loss: 0.5349 - val_acc: 0.8792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6134 - acc: 0.8516 - val_loss: 0.5397 - val_acc: 0.8748\n",
      "Epoch 62/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6127 - acc: 0.8503 - val_loss: 0.5341 - val_acc: 0.8776\n",
      "Epoch 63/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6097 - acc: 0.8518 - val_loss: 0.5363 - val_acc: 0.8789\n",
      "Epoch 64/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6101 - acc: 0.8511 - val_loss: 0.5628 - val_acc: 0.8711\n",
      "Epoch 65/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6086 - acc: 0.8520 - val_loss: 0.5567 - val_acc: 0.8715\n",
      "Epoch 66/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6114 - acc: 0.8524 - val_loss: 0.5169 - val_acc: 0.8867\n",
      "Epoch 67/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6059 - acc: 0.8551 - val_loss: 0.5384 - val_acc: 0.8784\n",
      "Epoch 68/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6061 - acc: 0.8538 - val_loss: 0.5249 - val_acc: 0.8851\n",
      "Epoch 69/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6103 - acc: 0.8536 - val_loss: 0.5773 - val_acc: 0.8647\n",
      "Epoch 70/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6052 - acc: 0.8548 - val_loss: 0.4914 - val_acc: 0.8931\n",
      "Epoch 71/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6069 - acc: 0.8527 - val_loss: 0.5149 - val_acc: 0.8868\n",
      "Epoch 72/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6042 - acc: 0.8530 - val_loss: 0.5690 - val_acc: 0.8696\n",
      "Epoch 73/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6021 - acc: 0.8546 - val_loss: 0.5138 - val_acc: 0.8873\n",
      "Epoch 74/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6020 - acc: 0.8545 - val_loss: 0.5245 - val_acc: 0.8771\n",
      "Epoch 75/125\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.5989 - acc: 0.8555 - val_loss: 0.4955 - val_acc: 0.8949\n",
      "Epoch 76/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6082 - acc: 0.8529 - val_loss: 0.4913 - val_acc: 0.8897\n",
      "Epoch 77/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5478 - acc: 0.8726 - val_loss: 0.4480 - val_acc: 0.9048\n",
      "Epoch 78/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5289 - acc: 0.8742 - val_loss: 0.4248 - val_acc: 0.9146\n",
      "Epoch 79/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5194 - acc: 0.8775 - val_loss: 0.3927 - val_acc: 0.9202\n",
      "Epoch 80/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5121 - acc: 0.8772 - val_loss: 0.4121 - val_acc: 0.9149\n",
      "Epoch 81/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.5005 - acc: 0.8803 - val_loss: 0.4169 - val_acc: 0.9118\n",
      "Epoch 82/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4958 - acc: 0.8814 - val_loss: 0.4258 - val_acc: 0.9063\n",
      "Epoch 83/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4948 - acc: 0.8806 - val_loss: 0.3834 - val_acc: 0.9201\n",
      "Epoch 84/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4859 - acc: 0.8823 - val_loss: 0.3809 - val_acc: 0.9182\n",
      "Epoch 85/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4884 - acc: 0.8808 - val_loss: 0.3947 - val_acc: 0.9116\n",
      "Epoch 86/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4854 - acc: 0.8804 - val_loss: 0.3865 - val_acc: 0.9150\n",
      "Epoch 87/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4796 - acc: 0.8818 - val_loss: 0.3911 - val_acc: 0.9133\n",
      "Epoch 88/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4783 - acc: 0.8824 - val_loss: 0.3731 - val_acc: 0.9198\n",
      "Epoch 89/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4784 - acc: 0.8819 - val_loss: 0.4049 - val_acc: 0.9103\n",
      "Epoch 90/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4728 - acc: 0.8846 - val_loss: 0.3652 - val_acc: 0.9217\n",
      "Epoch 91/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4726 - acc: 0.8831 - val_loss: 0.4156 - val_acc: 0.9090\n",
      "Epoch 92/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4699 - acc: 0.8836 - val_loss: 0.3576 - val_acc: 0.9202\n",
      "Epoch 93/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4706 - acc: 0.8815 - val_loss: 0.3529 - val_acc: 0.9261\n",
      "Epoch 94/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4696 - acc: 0.8829 - val_loss: 0.3846 - val_acc: 0.9136\n",
      "Epoch 95/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4685 - acc: 0.8839 - val_loss: 0.3817 - val_acc: 0.9130\n",
      "Epoch 96/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4641 - acc: 0.8844 - val_loss: 0.3775 - val_acc: 0.9172\n",
      "Epoch 97/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4695 - acc: 0.8838 - val_loss: 0.3432 - val_acc: 0.9271\n",
      "Epoch 98/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4625 - acc: 0.8839 - val_loss: 0.3642 - val_acc: 0.9199\n",
      "Epoch 99/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4637 - acc: 0.8840 - val_loss: 0.3915 - val_acc: 0.9086\n",
      "Epoch 100/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4619 - acc: 0.8853 - val_loss: 0.3884 - val_acc: 0.9095\n",
      "Epoch 101/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4626 - acc: 0.8845 - val_loss: 0.4037 - val_acc: 0.9058\n",
      "Epoch 102/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4353 - acc: 0.8936 - val_loss: 0.3425 - val_acc: 0.9254\n",
      "Epoch 103/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4266 - acc: 0.8952 - val_loss: 0.3195 - val_acc: 0.9314\n",
      "Epoch 104/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4249 - acc: 0.8954 - val_loss: 0.3271 - val_acc: 0.9322\n",
      "Epoch 105/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4144 - acc: 0.8978 - val_loss: 0.3428 - val_acc: 0.9239\n",
      "Epoch 106/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4170 - acc: 0.8968 - val_loss: 0.3245 - val_acc: 0.9298\n",
      "Epoch 107/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4135 - acc: 0.8981 - val_loss: 0.3197 - val_acc: 0.9330\n",
      "Epoch 108/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4143 - acc: 0.8985 - val_loss: 0.3075 - val_acc: 0.9334\n",
      "Epoch 109/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4096 - acc: 0.8991 - val_loss: 0.2950 - val_acc: 0.9379\n",
      "Epoch 110/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4035 - acc: 0.8996 - val_loss: 0.2987 - val_acc: 0.9382\n",
      "Epoch 111/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4050 - acc: 0.8988 - val_loss: 0.3006 - val_acc: 0.9358\n",
      "Epoch 112/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4040 - acc: 0.8988 - val_loss: 0.2985 - val_acc: 0.9368\n",
      "Epoch 113/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4044 - acc: 0.8998 - val_loss: 0.2993 - val_acc: 0.9372\n",
      "Epoch 114/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.4074 - acc: 0.8982 - val_loss: 0.3164 - val_acc: 0.9298\n",
      "Epoch 115/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3983 - acc: 0.9006 - val_loss: 0.2977 - val_acc: 0.9355\n",
      "Epoch 116/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3982 - acc: 0.9005 - val_loss: 0.3184 - val_acc: 0.9282\n",
      "Epoch 117/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3949 - acc: 0.9009 - val_loss: 0.2922 - val_acc: 0.9362\n",
      "Epoch 118/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3954 - acc: 0.9010 - val_loss: 0.2834 - val_acc: 0.9385\n",
      "Epoch 119/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3946 - acc: 0.9000 - val_loss: 0.3031 - val_acc: 0.9347\n",
      "Epoch 120/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3980 - acc: 0.8994 - val_loss: 0.2952 - val_acc: 0.9363\n",
      "Epoch 121/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3966 - acc: 0.8992 - val_loss: 0.3028 - val_acc: 0.9316\n",
      "Epoch 122/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3952 - acc: 0.9005 - val_loss: 0.3012 - val_acc: 0.9324\n",
      "Epoch 123/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3938 - acc: 0.9012 - val_loss: 0.2823 - val_acc: 0.9391\n",
      "Epoch 124/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3893 - acc: 0.9024 - val_loss: 0.2755 - val_acc: 0.9382\n",
      "Epoch 125/125\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3863 - acc: 0.9026 - val_loss: 0.2979 - val_acc: 0.9330\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "Accuracy:  0.933\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "num_classes=10\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=training_set_norm.shape[1:]))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.2))\n",
    " \n",
    "model2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.3))\n",
    " \n",
    "model2.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.3))\n",
    "# model2.add(Dropout(0.4))\n",
    " \n",
    "model2.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "datagen2 = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen2.fit(training_set_norm)\n",
    "opt_rms2 = RMSprop(lr=0.001,decay=1e-6)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=opt_rms2, metrics=['accuracy'])\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    return lrate\n",
    "history2 = model2.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=125,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "accuracy2 = model2.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy2[1])\n",
    "model2.save('./model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2748 - acc: 0.9289 - val_loss: 0.1665 - val_acc: 0.9658\n",
      "Epoch 242/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2692 - acc: 0.9319 - val_loss: 0.1678 - val_acc: 0.9657\n",
      "Epoch 243/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2730 - acc: 0.9295 - val_loss: 0.1640 - val_acc: 0.9681\n",
      "Epoch 244/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2675 - acc: 0.9309 - val_loss: 0.1678 - val_acc: 0.9664\n",
      "Epoch 245/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2656 - acc: 0.9324 - val_loss: 0.1666 - val_acc: 0.9659\n",
      "Epoch 246/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2688 - acc: 0.9317 - val_loss: 0.1635 - val_acc: 0.9671\n",
      "Epoch 247/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2656 - acc: 0.9323 - val_loss: 0.1635 - val_acc: 0.9677\n",
      "Epoch 248/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2678 - acc: 0.9319 - val_loss: 0.1651 - val_acc: 0.9665\n",
      "Epoch 249/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2678 - acc: 0.9306 - val_loss: 0.1658 - val_acc: 0.9663\n",
      "Epoch 250/300\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2683 - acc: 0.9298 - val_loss: 0.1600 - val_acc: 0.9683\n",
      "Epoch 251/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2671 - acc: 0.9322 - val_loss: 0.1631 - val_acc: 0.9682\n",
      "Epoch 252/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2624 - acc: 0.9330 - val_loss: 0.1607 - val_acc: 0.9690\n",
      "Epoch 253/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2651 - acc: 0.9320 - val_loss: 0.1595 - val_acc: 0.9689\n",
      "Epoch 254/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2630 - acc: 0.9337 - val_loss: 0.1571 - val_acc: 0.9703\n",
      "Epoch 255/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2637 - acc: 0.9324 - val_loss: 0.1675 - val_acc: 0.9667\n",
      "Epoch 256/300\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2635 - acc: 0.9329 - val_loss: 0.1584 - val_acc: 0.9696\n",
      "Epoch 257/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2683 - acc: 0.9311 - val_loss: 0.1624 - val_acc: 0.9681\n",
      "Epoch 258/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2632 - acc: 0.9331 - val_loss: 0.1677 - val_acc: 0.9659\n",
      "Epoch 259/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2661 - acc: 0.9315 - val_loss: 0.1577 - val_acc: 0.9689\n",
      "Epoch 260/300\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2629 - acc: 0.9328 - val_loss: 0.1601 - val_acc: 0.9685\n",
      "Epoch 261/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2607 - acc: 0.9336 - val_loss: 0.1608 - val_acc: 0.9671\n",
      "Epoch 262/300\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2653 - acc: 0.9317 - val_loss: 0.1589 - val_acc: 0.9685\n",
      "Epoch 263/300\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2613 - acc: 0.9322 - val_loss: 0.1562 - val_acc: 0.9700\n",
      "Epoch 264/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2630 - acc: 0.9311 - val_loss: 0.1575 - val_acc: 0.9696\n",
      "Epoch 265/300\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2639 - acc: 0.9315 - val_loss: 0.1547 - val_acc: 0.9708\n",
      "Epoch 266/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2625 - acc: 0.9322 - val_loss: 0.1597 - val_acc: 0.9707\n",
      "Epoch 267/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2596 - acc: 0.9330 - val_loss: 0.1561 - val_acc: 0.9705\n",
      "Epoch 268/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2641 - acc: 0.9322 - val_loss: 0.1603 - val_acc: 0.9690\n",
      "Epoch 269/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2621 - acc: 0.9317 - val_loss: 0.1586 - val_acc: 0.9704\n",
      "Epoch 270/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2625 - acc: 0.9318 - val_loss: 0.1631 - val_acc: 0.9668\n",
      "Epoch 271/300\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2611 - acc: 0.9319 - val_loss: 0.1640 - val_acc: 0.9670\n",
      "Epoch 272/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2628 - acc: 0.9322 - val_loss: 0.1555 - val_acc: 0.9707\n",
      "Epoch 273/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2605 - acc: 0.9323 - val_loss: 0.1573 - val_acc: 0.9681\n",
      "Epoch 274/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2626 - acc: 0.9322 - val_loss: 0.1565 - val_acc: 0.9693\n",
      "Epoch 275/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2629 - acc: 0.9311 - val_loss: 0.1611 - val_acc: 0.9662\n",
      "Epoch 276/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2609 - acc: 0.9325 - val_loss: 0.1540 - val_acc: 0.9706\n",
      "Epoch 277/300\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2597 - acc: 0.9325 - val_loss: 0.1560 - val_acc: 0.9706\n",
      "Epoch 278/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2595 - acc: 0.9340 - val_loss: 0.1561 - val_acc: 0.9703\n",
      "Epoch 279/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2605 - acc: 0.9332 - val_loss: 0.1531 - val_acc: 0.9707\n",
      "Epoch 280/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2597 - acc: 0.9319 - val_loss: 0.1553 - val_acc: 0.9694\n",
      "Epoch 281/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2586 - acc: 0.9327 - val_loss: 0.1539 - val_acc: 0.9699\n",
      "Epoch 282/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2635 - acc: 0.9321 - val_loss: 0.1592 - val_acc: 0.9670\n",
      "Epoch 283/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2583 - acc: 0.9336 - val_loss: 0.1569 - val_acc: 0.9697\n",
      "Epoch 284/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2596 - acc: 0.9331 - val_loss: 0.1542 - val_acc: 0.9692\n",
      "Epoch 285/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2582 - acc: 0.9320 - val_loss: 0.1549 - val_acc: 0.9695\n",
      "Epoch 286/300\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2582 - acc: 0.9327 - val_loss: 0.1536 - val_acc: 0.9700\n",
      "Epoch 287/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2590 - acc: 0.9339 - val_loss: 0.1569 - val_acc: 0.9681\n",
      "Epoch 288/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2603 - acc: 0.9335 - val_loss: 0.1516 - val_acc: 0.9709\n",
      "Epoch 289/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2596 - acc: 0.9326 - val_loss: 0.1529 - val_acc: 0.9699\n",
      "Epoch 290/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2573 - acc: 0.9338 - val_loss: 0.1584 - val_acc: 0.9679\n",
      "Epoch 291/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2551 - acc: 0.9337 - val_loss: 0.1501 - val_acc: 0.9714\n",
      "Epoch 292/300\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2554 - acc: 0.9340 - val_loss: 0.1500 - val_acc: 0.9714\n",
      "Epoch 293/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2601 - acc: 0.9327 - val_loss: 0.1487 - val_acc: 0.9700\n",
      "Epoch 294/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2589 - acc: 0.9325 - val_loss: 0.1472 - val_acc: 0.9718\n",
      "Epoch 295/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2567 - acc: 0.9331 - val_loss: 0.1547 - val_acc: 0.9702\n",
      "Epoch 296/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2545 - acc: 0.9340 - val_loss: 0.1545 - val_acc: 0.9691\n",
      "Epoch 297/300\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2591 - acc: 0.9328 - val_loss: 0.1497 - val_acc: 0.9711\n",
      "Epoch 298/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2564 - acc: 0.9337 - val_loss: 0.1553 - val_acc: 0.9691\n",
      "Epoch 299/300\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2527 - acc: 0.9350 - val_loss: 0.1506 - val_acc: 0.9713\n",
      "Epoch 300/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.2589 - acc: 0.9333 - val_loss: 0.1438 - val_acc: 0.9739\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "Accuracy:  0.9739\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 125:\n",
    "        lrate = 0.0002\n",
    "    if epoch > 150:\n",
    "        lrate = 0.0001\n",
    "    if epoch > 180:\n",
    "        lrate = 0.00007\n",
    "    if epoch > 210:\n",
    "        lrate = 0.00005\n",
    "    if epoch > 240:\n",
    "        lrate = 0.00003\n",
    "    if epoch > 300:\n",
    "        lrate = 0.00001\n",
    "    return lrate\n",
    "model20 = load_model('./model20.h5')\n",
    "history20 = model20.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=300,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=240)\n",
    "accuracy20 = model20.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy20[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20.save('./modelWRONG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model3.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model22 = load_model('./model21.h5')\n",
    "history22 = model22.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=200,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=145)\n",
    "accuracy22 = model22.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy22[1])\n",
    "model22.save('./model22.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model22.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00001\n",
    "    return lrate\n",
    "model23 = load_model('./model22.h5')\n",
    "history23 = model23.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=220,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=200)\n",
    "accuracy23 = model23.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy22[1])\n",
    "model23.save('./model23.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model23.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00001\n",
    "    if epoch > 220:\n",
    "        lrate = 0.0000001\n",
    "    return lrate\n",
    "model24 = load_model('./model23.h5')\n",
    "history24 = model24.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=225,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=220)\n",
    "accuracy24 = model24.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy24[1])\n",
    "model24.save('./model24.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model24.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00001\n",
    "    if epoch > 220:\n",
    "        lrate = 0.000001\n",
    "    return lrate\n",
    "model3 = model\n",
    "history3 = model3.fit_generator(datagen2.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=150,\\\n",
    "                    verbose=0,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=125)\n",
    "accuracy3 = model3.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy3[1])\n",
    "model3.save('./model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(training_set,axis=(0,1,2,3))\n",
    "std = np.std(training_set,axis=(0,1,2,3))\n",
    "x_train = (training_set-mean)/(std+1e-7)\n",
    "x_test = (test_data-mean)/(std+1e-7)\n",
    "num_classes = 10\n",
    "y_train = training_label_one_hot_encode\n",
    "y_test = test_label_one_hot_encoded\n",
    "\n",
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(Dropout(0.4))\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model4.summary()\n",
    "\n",
    "#data augmentation\n",
    "datagen4 = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen4.fit(x_train)\n",
    "\n",
    "#training\n",
    "batch_size = 64\n",
    "epochs=25\n",
    "opt_rms = RMSprop(lr=0.001,decay=1e-6)\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "hitsory41= model4.fit_generator(datagen4.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model4.save_weights('cifar10_normal_rms_ep75.h5')\n",
    "\n",
    "opt_rms = RMSprop(lr=0.0005,decay=1e-6)\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "hitsory42 = model4.fit_generator(datagen4.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model4.save_weights('cifar10_normal_rms_ep100.h5')\n",
    "\n",
    "opt_rms = RMSprop(lr=0.0003,decay=1e-6)\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "hitsory43 = model4.fit_generator(datagen4.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model4.save_weights('cifar10_normal_rms_ep125.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.load('/kaggle/input/cs4487cp/test_data/y_test.npy')\n",
    "pp_norm = (pp-mean)/(std+1e-7)\n",
    "test_res = []\n",
    "for i in model4.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "# summarize_diagnostics(history41)\n",
    "# summarize_diagnostics(history42)\n",
    "# summarize_diagnostics(history43)\n",
    "\n",
    "df = pd.DataFrame({'Category':test_res})\n",
    "df['Index'] = df.index\n",
    "df = df[['Index','Category']]\n",
    "df.to_csv('./test_res4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoint\n",
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "\n",
    "'''EfficientNet in PyTorch.\n",
    "Paper: \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\".\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def main(resume,lr,epochAdd):\n",
    "    import torch.nn as nn\n",
    "    class Block(nn.Module):\n",
    "        '''expand + depthwise + pointwise + squeeze-excitation'''\n",
    "\n",
    "        def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "            super(Block, self).__init__()\n",
    "            self.stride = stride\n",
    "\n",
    "            planes = expansion * in_planes\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "            self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                                   stride=stride, padding=1, groups=planes, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "            self.conv3 = nn.Conv2d(\n",
    "                planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "            self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "            self.shortcut = nn.Sequential()\n",
    "            if stride == 1 and in_planes != out_planes:\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_planes, out_planes, kernel_size=1,\n",
    "                              stride=1, padding=0, bias=False),\n",
    "                    nn.BatchNorm2d(out_planes),\n",
    "                )\n",
    "\n",
    "            # SE layers\n",
    "            self.fc1 = nn.Conv2d(out_planes, out_planes//16, kernel_size=1)\n",
    "            self.fc2 = nn.Conv2d(out_planes//16, out_planes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(self.conv1(x)))\n",
    "            out = F.relu(self.bn2(self.conv2(out)))\n",
    "            out = self.bn3(self.conv3(out))\n",
    "            shortcut = self.shortcut(x) if self.stride == 1 else out\n",
    "            # Squeeze-Excitation\n",
    "            w = F.avg_pool2d(out, out.size(2))\n",
    "            w = F.relu(self.fc1(w))\n",
    "            w = self.fc2(w).sigmoid()\n",
    "            out = out * w + shortcut\n",
    "            return out\n",
    "\n",
    "\n",
    "    class EfficientNet(nn.Module):\n",
    "        def __init__(self, cfg, num_classes=10):\n",
    "            super(EfficientNet, self).__init__()\n",
    "            self.cfg = cfg\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                                   stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.layers = self._make_layers(in_planes=32)\n",
    "            self.linear = nn.Linear(cfg[-1][1], num_classes)\n",
    "\n",
    "        def _make_layers(self, in_planes):\n",
    "            layers = []\n",
    "            for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "                strides = [stride] + [1]*(num_blocks-1)\n",
    "                for stride in strides:\n",
    "                    layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                    in_planes = out_planes\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(self.conv1(x)))\n",
    "            out = self.layers(out)\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.linear(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "    def EfficientNetB0():\n",
    "        # (expansion, out_planes, num_blocks, stride)\n",
    "        cfg = [(1,  16, 1, 2),\n",
    "               (6,  24, 2, 1),\n",
    "               (6,  40, 2, 2),\n",
    "               (6,  80, 3, 2),\n",
    "               (6, 112, 3, 1),\n",
    "               (6, 192, 4, 2),\n",
    "               (6, 320, 1, 2)]\n",
    "        return EfficientNet(cfg)\n",
    "\n",
    "\n",
    "#     def test():\n",
    "#         net = EfficientNetB0()\n",
    "#         x = torch.randn(2, 3, 32, 32)\n",
    "#         y = net(x)\n",
    "#         print(y.shape)\n",
    "\n",
    "\n",
    "    # test()\n",
    "    import os\n",
    "    import sys\n",
    "    import time\n",
    "    import math\n",
    "\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.init as init\n",
    "    \n",
    "    \n",
    "    def get_mean_and_std(dataset):\n",
    "        '''Compute the mean and std value of dataset.'''\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "        mean = torch.zeros(3)\n",
    "        std = torch.zeros(3)\n",
    "        print('==> Computing mean and std..')\n",
    "        for inputs, targets in dataloader:\n",
    "            for i in range(3):\n",
    "                mean[i] += inputs[:,i,:,:].mean()\n",
    "                std[i] += inputs[:,i,:,:].std()\n",
    "        mean.div_(len(dataset))\n",
    "        std.div_(len(dataset))\n",
    "        return mean, std\n",
    "\n",
    "    def init_params(net):\n",
    "        '''Init layer parameters.'''\n",
    "        for m in net.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal(m.weight, mode='fan_out')\n",
    "                if m.bias:\n",
    "                    init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant(m.weight, 1)\n",
    "                init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal(m.weight, std=1e-3)\n",
    "                if m.bias:\n",
    "                    init.constant(m.bias, 0)\n",
    "\n",
    "    term_width = 100\n",
    "\n",
    "    TOTAL_BAR_LENGTH = 65.\n",
    "    last_time = time.time()\n",
    "    begin_time = last_time\n",
    "    def progress_bar(current, total, msg=None):\n",
    "        global last_time, begin_time\n",
    "        if current == 0:\n",
    "            begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "        cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "        rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "        sys.stdout.write(' [')\n",
    "        for i in range(cur_len):\n",
    "            sys.stdout.write('=')\n",
    "        sys.stdout.write('>')\n",
    "        for i in range(rest_len):\n",
    "            sys.stdout.write('.')\n",
    "        sys.stdout.write(']')\n",
    "\n",
    "        cur_time = time.time()\n",
    "        step_time = cur_time - last_time\n",
    "        last_time = cur_time\n",
    "        tot_time = cur_time - begin_time\n",
    "\n",
    "        L = []\n",
    "        L.append('  Step: %s' % format_time(step_time))\n",
    "        L.append(' | Tot: %s' % format_time(tot_time))\n",
    "        if msg:\n",
    "            L.append(' | ' + msg)\n",
    "\n",
    "        msg = ''.join(L)\n",
    "        sys.stdout.write(msg)\n",
    "        for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "            sys.stdout.write(' ')\n",
    "\n",
    "        # Go back to the center of the bar.\n",
    "        for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "            sys.stdout.write('\\b')\n",
    "        sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "        if current < total-1:\n",
    "            sys.stdout.write('\\r')\n",
    "        else:\n",
    "            sys.stdout.write('\\n')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def format_time(seconds):\n",
    "        days = int(seconds / 3600/24)\n",
    "        seconds = seconds - days*3600*24\n",
    "        hours = int(seconds / 3600)\n",
    "        seconds = seconds - hours*3600\n",
    "        minutes = int(seconds / 60)\n",
    "        seconds = seconds - minutes*60\n",
    "        secondsf = int(seconds)\n",
    "        seconds = seconds - secondsf\n",
    "        millis = int(seconds*1000)\n",
    "\n",
    "        f = ''\n",
    "        i = 1\n",
    "        if days > 0:\n",
    "            f += str(days) + 'D'\n",
    "            i += 1\n",
    "        if hours > 0 and i <= 2:\n",
    "            f += str(hours) + 'h'\n",
    "            i += 1\n",
    "        if minutes > 0 and i <= 2:\n",
    "            f += str(minutes) + 'm'\n",
    "            i += 1\n",
    "        if secondsf > 0 and i <= 2:\n",
    "            f += str(secondsf) + 's'\n",
    "            i += 1\n",
    "        if millis > 0 and i <= 2:\n",
    "            f += str(millis) + 'ms'\n",
    "            i += 1\n",
    "        if f == '':\n",
    "            f = '0ms'\n",
    "        return f\n",
    "\n",
    "\n",
    "    # parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "    # parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "    # parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "    # args = parser.parse_args()\n",
    "    best_acc = 0  # best test accuracy\n",
    "    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "    # Data\n",
    "    print('==> Preparing data..')\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # Model\n",
    "    print('==> Building model..')\n",
    "    # net = VGG('VGG19')\n",
    "    # net = ResNet18()\n",
    "    # net = PreActResNet18()\n",
    "    # net = GoogLeNet()\n",
    "    # net = DenseNet121()\n",
    "    # net = ResNeXt29_2x64d()\n",
    "    # net = MobileNet()\n",
    "    # net = MobileNetV2()\n",
    "    # net = DPN92()\n",
    "    # net = ShuffleNetG2()\n",
    "    # net = SENet18()\n",
    "    # net = ShuffleNetV2(1)\n",
    "    net = EfficientNetB0()\n",
    "    net = net.to(device)\n",
    "    if device == 'cuda':\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    if resume:\n",
    "        # Load checkpoint.\n",
    "        print('==> Resuming from checkpoint..')\n",
    "        assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "        checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        best_acc = checkpoint['acc']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    # Training\n",
    "    def train(epoch):\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    def test(epoch):\n",
    "        global best_acc\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                    % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        # Save checkpoint.\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_acc:\n",
    "            print('Saving..')\n",
    "            state = {\n",
    "                'net': net.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.pth')\n",
    "            best_acc = acc\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch+epochAdd):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "    return net\n",
    "lrate= [0.1,0.01,0.001]\n",
    "epochAdd=[150,100,100]\n",
    "nettt = []\n",
    "for i in range(3):\n",
    "    nettt.append(main(i!=0,lrate[i],epochAdd[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -O ./data/cifar-10-python.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "pp_torch = transform_test(pp)\n",
    "nettt[len(nettt)-1].eval()\n",
    "with torch.no_grad():\n",
    "    input = pp_torch.to(device)\n",
    "    outputs = nettt[len(nettt)-1](inputs)\n",
    "    _, predicted = outputs.max(1)\n",
    "#     for batch_idx, (inputs, targets) in enumerate(pploader):\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         outputs = nettt[len(nettt)-1](inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "#         test_loss += loss.item()\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         total += targets.size(0)\n",
    "#         correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#         progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "#             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model4.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.load('./y_test.npy')\n",
    "pp_norm = normalization(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "# for i in range(0,100,5):\n",
    "#     plotImages(pp[i:],test_res[i:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "# \tfilename = sys.argv[0].split('/')[-1]\n",
    "# \tpyplot.savefig(filename + '_plot.png')\n",
    "# \tpyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_diagnostics(history20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2 = model2.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /kaggle/input/cs4487cp/test_data/test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Category':test_res})\n",
    "df['Index'] = df.index\n",
    "df = df[['Index','Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./test_res4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(test_res, open('/kaggle/output/test_res','wb'))\n",
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_norm\n",
    "test_data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [pp[3]]:\n",
    "    for j in training_set:\n",
    "        if (i == j).all():\n",
    "            print('WTF?')\n",
    "    for j in test_data:\n",
    "        if (i == j).all():\n",
    "            print('WTF?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [15]:\n",
    "    for j in range(1):\n",
    "        print('try: '+ str(j))\n",
    "        print('epoch: '+str(i))\n",
    "        model = Sequential([\n",
    "            Conv2D(64, kernel_size=3, activation='relu',input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "            MaxPooling2D((2,2),padding='same'),\n",
    "            Conv2D(128, kernel_size=3, activation='relu'),\n",
    "            MaxPooling2D((2,2),padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        history = model.fit(\n",
    "            x=training_set_norm,\n",
    "            y=training_label_one_hot_encode,\n",
    "            epochs=i,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "        )\n",
    "        accuracy = model.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "        res[(j,i)] = accuracy[1]\n",
    "        print(\"Accuracy: \",accuracy[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [5,10,15,20]:\n",
    "    print('epoch: '+str(i))\n",
    "    for j in range(3):\n",
    "        print('try: '+ str(j))\n",
    "        print('acc: '+ str(res[(j,i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import EfficientNetB0 as Net\n",
    "from efficientnet import center_crop_and_resize, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = Net(weights=\"imagenet\", include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full4, num_outputs=10, activation_fn=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n",
      "WARNING:tensorflow:From <ipython-input-40-b331ba17c6b5>:272: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preprocess_batch_1.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b331ba17c6b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mn_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mload_preprocess_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m                 \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-b331ba17c6b5>\u001b[0m in \u001b[0;36mload_preprocess_training_batch\u001b[1;34m(batch_id, batch_size)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m    131\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'preprocess_batch_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.p'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;31m# Return the training data in batches of size <batch_size> or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preprocess_batch_1.p'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
