{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5419615088256838802\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9215183422\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11676961479569839813\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization,Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file, train=True):\n",
    "    import pickle\n",
    "    with open('./cifar10-python/cifar-10-batches-py/'+(('data_batch_'+str(file)) if train else 'test_batch'), 'rb') as fo:\n",
    "        dict_d = pickle.load(fo, encoding='latin1')\n",
    "    return np.reshape(dict_d['data'],(10000,3,32,32)).transpose(0, 2, 3, 1), dict_d['labels']\n",
    "def normalization(x):\n",
    "    return x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "training_label = []\n",
    "for i in range(1,6):\n",
    "    x,y = unpickle(i)\n",
    "    training_set.extend(x) \n",
    "    training_label.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data,test_label = unpickle(0,train=False)\n",
    "test_data_norm = normalization(np.array(test_data))\n",
    "test_label_one_hot_encoded = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_norm = np.array(training_set) / 255\n",
    "training_label_one_hot_encode = to_categorical(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.extend(test_data)\n",
    "training_label_one_hot_encode = np.concatenate((training_label_one_hot_encode,test_label_one_hot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_norm = np.array(training_set) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label_one_hot_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "datagen.fit(training_set_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name = [\n",
    "\"airplane\",\n",
    "\"automobile\",\n",
    "\"bird\",\n",
    "\"cat\",\n",
    "\"deer\",\n",
    "\"dog\",\n",
    "\"frog\",\n",
    "\"horse\",\n",
    "\"ship\",\n",
    "\"truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [0]*10\n",
    "for i in training_label:\n",
    "    counts[i] += 1\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr,lab):\n",
    "    from matplotlib import pyplot as plt\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    for i in lab[:5]:\n",
    "        print(labels_name[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog truck truck deer automobile "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile bird horse ship cat "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deer horse horse bird truck "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck truck cat bird frog "
     ]
    }
   ],
   "source": [
    "for i in range(0,20,5):\n",
    "    plotImages(training_set_norm[i:i+5],training_label[i:i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Data reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 2.0276 - acc: 0.2220A: 0s - loss: 2.0402 - ac\n",
      "Epoch 2/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.6642 - acc: 0.3953\n",
      "Epoch 3/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.4896 - acc: 0.4700\n",
      "Epoch 4/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.3752 - acc: 0.5288\n",
      "Epoch 5/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.3227 - acc: 0.5485\n",
      "Epoch 6/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.3037 - acc: 0.5576\n",
      "Epoch 7/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.2132 - acc: 0.5937\n",
      "Epoch 8/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.2462 - acc: 0.5900\n",
      "Epoch 9/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.2555 - acc: 0.5874\n",
      "Epoch 10/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.2914 - acc: 0.5780\n",
      "Epoch 11/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.2965 - acc: 0.5687\n",
      "Epoch 12/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0836 - acc: 0.6413\n",
      "Epoch 13/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0515 - acc: 0.6555\n",
      "Epoch 14/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0365 - acc: 0.6600\n",
      "Epoch 15/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0429 - acc: 0.6610\n",
      "Epoch 16/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0425 - acc: 0.6567\n",
      "Epoch 17/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0483 - acc: 0.6568\n",
      "Epoch 18/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0543 - acc: 0.6570\n",
      "Epoch 19/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0598 - acc: 0.6581\n",
      "Epoch 20/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0621 - acc: 0.6573\n",
      "Epoch 21/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0600 - acc: 0.6576\n",
      "Epoch 22/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0645 - acc: 0.6572\n",
      "Epoch 23/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0735 - acc: 0.6517\n",
      "Epoch 24/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0708 - acc: 0.6529\n",
      "Epoch 25/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0670 - acc: 0.6541\n",
      "Epoch 26/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0665 - acc: 0.6553\n",
      "Epoch 27/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0757 - acc: 0.6530\n",
      "Epoch 28/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0657 - acc: 0.6540\n",
      "Epoch 29/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0627 - acc: 0.6569\n",
      "Epoch 30/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0670 - acc: 0.6575\n",
      "Epoch 31/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0706 - acc: 0.6561\n",
      "Epoch 32/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0519 - acc: 0.6572\n",
      "Epoch 33/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0637 - acc: 0.6578\n",
      "Epoch 34/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0758 - acc: 0.6542\n",
      "Epoch 35/170\n",
      "938/937 [==============================] - 8s 8ms/step - loss: 1.0661 - acc: 0.6548\n",
      "Epoch 36/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0576 - acc: 0.6573\n",
      "Epoch 37/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0711 - acc: 0.6540\n",
      "Epoch 38/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0633 - acc: 0.6542\n",
      "Epoch 39/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0760 - acc: 0.6542\n",
      "Epoch 40/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0616 - acc: 0.6568\n",
      "Epoch 41/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0505 - acc: 0.6578\n",
      "Epoch 42/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0749 - acc: 0.6547\n",
      "Epoch 43/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0704 - acc: 0.6535\n",
      "Epoch 44/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0625 - acc: 0.6529\n",
      "Epoch 45/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0496 - acc: 0.6591\n",
      "Epoch 46/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0568 - acc: 0.6583\n",
      "Epoch 47/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0519 - acc: 0.6605\n",
      "Epoch 48/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0578 - acc: 0.6586\n",
      "Epoch 49/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0584 - acc: 0.6599\n",
      "Epoch 50/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0696 - acc: 0.6563\n",
      "Epoch 51/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0620 - acc: 0.6548\n",
      "Epoch 52/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0571 - acc: 0.6581\n",
      "Epoch 53/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0626 - acc: 0.6564\n",
      "Epoch 54/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0701 - acc: 0.6598\n",
      "Epoch 55/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0538 - acc: 0.6597\n",
      "Epoch 56/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0752 - acc: 0.6580\n",
      "Epoch 57/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0558 - acc: 0.6584\n",
      "Epoch 58/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0761 - acc: 0.6555\n",
      "Epoch 59/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0573 - acc: 0.6570\n",
      "Epoch 60/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0616 - acc: 0.6537\n",
      "Epoch 61/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0725 - acc: 0.6567\n",
      "Epoch 62/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0679 - acc: 0.6582\n",
      "Epoch 63/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0697 - acc: 0.6571\n",
      "Epoch 64/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0551 - acc: 0.6608\n",
      "Epoch 65/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0655 - acc: 0.6576\n",
      "Epoch 66/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0585 - acc: 0.6619\n",
      "Epoch 67/170\n",
      "938/937 [==============================] - 8s 9ms/step - loss: 1.0616 - acc: 0.6601\n",
      "Epoch 68/170\n",
      "545/937 [================>.............] - ETA: 3s - loss: 1.0737 - acc: 0.6537"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-da3cf9fb9961>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m170\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    102\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_label_one_hot_encoded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[1;32m--> 176\u001b[1;33m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1940\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = Sequential([\n",
    "#     Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "#     MaxPooling2D((2,2),padding='same'),\n",
    "#     Dropout(0.2),\n",
    "#     Flatten(),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# train test merge:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=training_set_norm.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "datagen.fit(training_set_norm)\n",
    "\n",
    "model.compile(optimizer= opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 5:\n",
    "        lrate = 0.0007\n",
    "    if epoch > 10:\n",
    "        lrate = 0.00005\n",
    "    if epoch > 25:\n",
    "        lrate = 0.0000001\n",
    "    if epoch > 50:\n",
    "        lrate = 0.00000005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.00000001\n",
    "    if epoch > 150:\n",
    "        lrate = 0.000000005\n",
    "    return lrate\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\n",
    "    steps_per_epoch=len(training_set_norm) / 16, \n",
    "    epochs=170,\n",
    "    workers=8,\n",
    "    callbacks=[LearningRateScheduler(lr_schedule)]\n",
    ")\n",
    "accuracy = model.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0606 - acc: 0.6590\n",
      "Epoch 70/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0595 - acc: 0.6594: 0s - loss: 1.0597 - \n",
      "Epoch 71/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0579 - acc: 0.6585\n",
      "Epoch 72/170\n",
      "3750/3750 [==============================] - 29s 8ms/step - loss: 1.0561 - acc: 0.6581\n",
      "Epoch 73/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0606 - acc: 0.6602\n",
      "Epoch 74/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0577 - acc: 0.6592\n",
      "Epoch 75/170\n",
      "3750/3750 [==============================] - 28s 8ms/step - loss: 1.0622 - acc: 0.6573\n",
      "Epoch 76/170\n",
      "2739/3750 [====================>.........] - ETA: 7s - loss: 1.0603 - acc: 0.6586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7d6a5480169a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m68\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_label_one_hot_encoded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[1;32m--> 176\u001b[1;33m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1940\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model1 = load_model('./model.h5')\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 5:\n",
    "        lrate = 0.0007\n",
    "    if epoch > 10:\n",
    "        lrate = 0.00005\n",
    "    if epoch > 25:\n",
    "        lrate = 0.0000001\n",
    "    if epoch > 50:\n",
    "        lrate = 0.000000005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.000000001\n",
    "    if epoch > 150:\n",
    "        lrate = 0.0000000005\n",
    "    return lrate\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\n",
    "    steps_per_epoch=len(training_set_norm) / 16, \n",
    "    epochs=170,\n",
    "    workers=4,\n",
    "    callbacks=[LearningRateScheduler(lr_schedule)],\n",
    "    initial_epoch=68\n",
    ")\n",
    "accuracy = model.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 1.4872 - acc: 0.4953 - val_loss: 1.3251 - val_acc: 0.5733\n",
      "Epoch 2/250\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 1.1593 - acc: 0.6400 - val_loss: 1.0098 - val_acc: 0.6911\n",
      "Epoch 3/250\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 1.0840 - acc: 0.6811 - val_loss: 0.8833 - val_acc: 0.7574\n",
      "Epoch 4/250\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 1.0615 - acc: 0.7030 - val_loss: 0.8989 - val_acc: 0.7503\n",
      "Epoch 5/250\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 1.0577 - acc: 0.7135 - val_loss: 1.0242 - val_acc: 0.7165\n",
      "Epoch 6/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0427 - acc: 0.7267 - val_loss: 0.9410 - val_acc: 0.7575\n",
      "Epoch 7/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0534 - acc: 0.7302 - val_loss: 0.8541 - val_acc: 0.7842\n",
      "Epoch 8/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0564 - acc: 0.7335 - val_loss: 0.9045 - val_acc: 0.7672\n",
      "Epoch 9/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0667 - acc: 0.7398 - val_loss: 0.9155 - val_acc: 0.7727\n",
      "Epoch 10/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0729 - acc: 0.7401 - val_loss: 0.8634 - val_acc: 0.7944\n",
      "Epoch 11/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0665 - acc: 0.7438 - val_loss: 1.0593 - val_acc: 0.7319\n",
      "Epoch 12/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0627 - acc: 0.7447 - val_loss: 1.0414 - val_acc: 0.7561\n",
      "Epoch 13/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0717 - acc: 0.7505 - val_loss: 0.9372 - val_acc: 0.7779\n",
      "Epoch 14/250\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 1.0871 - acc: 0.7494 - val_loss: 1.0012 - val_acc: 0.7685\n",
      "Epoch 15/250\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 1.0752 - acc: 0.7492 - val_loss: 1.2100 - val_acc: 0.7194\n",
      "Epoch 16/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 1.0811 - acc: 0.7537 - val_loss: 0.8442 - val_acc: 0.8101\n",
      "Epoch 17/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 1.0730 - acc: 0.7577 - val_loss: 0.9024 - val_acc: 0.7915\n",
      "Epoch 18/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 1.0644 - acc: 0.7598 - val_loss: 0.9162 - val_acc: 0.7857\n",
      "Epoch 19/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 1.0592 - acc: 0.7626 - val_loss: 0.8379 - val_acc: 0.8223\n",
      "Epoch 20/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 1.0652 - acc: 0.7624 - val_loss: 1.1253 - val_acc: 0.7492\n",
      "Epoch 21/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 1.0599 - acc: 0.7657 - val_loss: 0.8067 - val_acc: 0.8350\n",
      "Epoch 22/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 1.0257 - acc: 0.7722 - val_loss: 0.8178 - val_acc: 0.8247\n",
      "Epoch 23/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 1.0039 - acc: 0.7782 - val_loss: 1.0545 - val_acc: 0.7909\n",
      "Epoch 24/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.9853 - acc: 0.7809 - val_loss: 0.8844 - val_acc: 0.8039\n",
      "Epoch 25/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.9738 - acc: 0.7811 - val_loss: 0.9453 - val_acc: 0.7902\n",
      "Epoch 26/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.9577 - acc: 0.7863 - val_loss: 0.7271 - val_acc: 0.8532\n",
      "Epoch 27/250\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.9396 - acc: 0.7864 - val_loss: 0.7568 - val_acc: 0.8326\n",
      "Epoch 28/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.9230 - acc: 0.7891 - val_loss: 0.7470 - val_acc: 0.8439\n",
      "Epoch 29/250\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.9163 - acc: 0.7941 - val_loss: 0.6702 - val_acc: 0.8672\n",
      "Epoch 30/250\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.9070 - acc: 0.7932 - val_loss: 0.7306 - val_acc: 0.8497\n",
      "Epoch 31/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.9053 - acc: 0.7968 - val_loss: 0.7132 - val_acc: 0.8492\n",
      "Epoch 32/250\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.8957 - acc: 0.7983 - val_loss: 0.7735 - val_acc: 0.8266\n",
      "Epoch 33/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8902 - acc: 0.8029 - val_loss: 0.7162 - val_acc: 0.8489\n",
      "Epoch 34/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8800 - acc: 0.8052 - val_loss: 0.6555 - val_acc: 0.8677\n",
      "Epoch 35/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.8677 - acc: 0.8057 - val_loss: 0.7176 - val_acc: 0.8523\n",
      "Epoch 36/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8641 - acc: 0.8091 - val_loss: 0.7282 - val_acc: 0.8454\n",
      "Epoch 37/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8675 - acc: 0.8080 - val_loss: 0.6815 - val_acc: 0.8650\n",
      "Epoch 38/250\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.8595 - acc: 0.8103 - val_loss: 0.6244 - val_acc: 0.8787\n",
      "Epoch 39/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8644 - acc: 0.8107 - val_loss: 0.7117 - val_acc: 0.8495\n",
      "Epoch 40/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8644 - acc: 0.8110 - val_loss: 0.6440 - val_acc: 0.8770\n",
      "Epoch 41/250\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.8558 - acc: 0.8144 - val_loss: 0.7136 - val_acc: 0.8502\n",
      "Epoch 42/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8521 - acc: 0.8163 - val_loss: 0.6442 - val_acc: 0.8717\n",
      "Epoch 43/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8621 - acc: 0.8132 - val_loss: 0.6671 - val_acc: 0.8614\n",
      "Epoch 44/250\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.8577 - acc: 0.8131 - val_loss: 0.6736 - val_acc: 0.8606\n",
      "Epoch 45/250\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.8599 - acc: 0.8147 - val_loss: 0.6332 - val_acc: 0.8744\n",
      "Epoch 46/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8616 - acc: 0.8154 - val_loss: 0.7365 - val_acc: 0.8457\n",
      "Epoch 47/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8568 - acc: 0.8149 - val_loss: 0.7168 - val_acc: 0.8517\n",
      "Epoch 48/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.8601 - acc: 0.8176 - val_loss: 0.7948 - val_acc: 0.8379\n",
      "Epoch 49/250\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.8544 - acc: 0.8180 - val_loss: 0.6145 - val_acc: 0.8804\n",
      "Epoch 50/250\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 0.8649 - acc: 0.8178 - val_loss: 0.6284 - val_acc: 0.8845\n",
      "Epoch 51/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.8696 - acc: 0.8151 - val_loss: 0.6303 - val_acc: 0.8776\n",
      "Epoch 52/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8837 - acc: 0.8155 - val_loss: 0.6722 - val_acc: 0.8706\n",
      "Epoch 53/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.8789 - acc: 0.8152 - val_loss: 0.7608 - val_acc: 0.8640\n",
      "Epoch 54/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8734 - acc: 0.8160 - val_loss: 0.6784 - val_acc: 0.8672\n",
      "Epoch 55/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8843 - acc: 0.8182 - val_loss: 0.6293 - val_acc: 0.8856\n",
      "Epoch 56/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8644 - acc: 0.8200 - val_loss: 0.6676 - val_acc: 0.8780\n",
      "Epoch 57/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8762 - acc: 0.8180 - val_loss: 0.7173 - val_acc: 0.8561\n",
      "Epoch 58/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8745 - acc: 0.8197 - val_loss: 0.6783 - val_acc: 0.8841\n",
      "Epoch 59/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8863 - acc: 0.8188 - val_loss: 0.6983 - val_acc: 0.8675\n",
      "Epoch 60/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.8643 - acc: 0.8199 - val_loss: 0.6605 - val_acc: 0.8793\n",
      "Epoch 61/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8845 - acc: 0.8200 - val_loss: 0.6734 - val_acc: 0.8821\n",
      "Epoch 62/250\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.8949 - acc: 0.8180 - val_loss: 0.6167 - val_acc: 0.8886\n",
      "Epoch 63/250\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.8842 - acc: 0.8198 - val_loss: 0.7078 - val_acc: 0.8762\n",
      "Epoch 64/250\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.8829 - acc: 0.8179 - val_loss: 0.6562 - val_acc: 0.8802\n",
      "Epoch 65/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.8882 - acc: 0.8197 - val_loss: 0.7694 - val_acc: 0.8514\n",
      "Epoch 66/250\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.8981 - acc: 0.8184 - val_loss: 0.7020 - val_acc: 0.8775\n",
      "Epoch 67/250\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.8985 - acc: 0.8187 - val_loss: 0.6521 - val_acc: 0.8828\n",
      "Epoch 68/250\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.8921 - acc: 0.8198 - val_loss: 0.6249 - val_acc: 0.8867\n",
      "Epoch 69/250\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 0.8892 - acc: 0.8210 - val_loss: 0.6759 - val_acc: 0.8763\n",
      "Epoch 70/250\n",
      "50720/60000 [========================>.....] - ETA: 2s - loss: 0.9017 - acc: 0.8193"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-4bfc5cbbd5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlrate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m history2 = model2.fit(training_set_norm, training_label_one_hot_encode, batch_size=32,epochs=250,\n\u001b[1;32m---> 70\u001b[1;33m                     verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)])\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[0maccuracy2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_label_one_hot_encoded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "num_classes=10\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=training_set_norm.shape[1:]))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.2))\n",
    " \n",
    "model2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "model2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.3))\n",
    " \n",
    "model2.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model2.add(Activation('elu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.3))\n",
    "# model2.add(Dropout(0.4))\n",
    " \n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(512))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(1024))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "# datagen2 = ImageDataGenerator(\n",
    "#     rotation_range=15,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     horizontal_flip=True,\n",
    "#     )\n",
    "datagen2.fit(training_set_norm)\n",
    "opt_rms2 = RMSprop(lr=0.001,decay=1e-6)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=opt_rms2, metrics=['accuracy'])\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 150:\n",
    "        lrate = 0.0001\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00007\n",
    "    return lrate\n",
    "history2 = model2.fit(training_set_norm, training_label_one_hot_encode, batch_size=32,epochs=250,\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "accuracy2 = model2.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy2[1])\n",
    "model2.save('./model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/180\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3241 - acc: 0.9189 - val_loss: 0.2177 - val_acc: 0.9556\n",
      "Epoch 162/180\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3260 - acc: 0.9182 - val_loss: 0.2286 - val_acc: 0.9507\n",
      "Epoch 163/180\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3224 - acc: 0.9179 - val_loss: 0.2333 - val_acc: 0.9490\n",
      "Epoch 164/180\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3234 - acc: 0.9177 - val_loss: 0.2177 - val_acc: 0.9549\n",
      "Epoch 165/180\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3235 - acc: 0.9182 - val_loss: 0.2119 - val_acc: 0.9562\n",
      "Epoch 166/180\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3198 - acc: 0.9202 - val_loss: 0.2337 - val_acc: 0.9495\n",
      "Epoch 167/180\n",
      "1527/1875 [=======================>......] - ETA: 3s - loss: 0.3220 - acc: 0.9181"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 125:\n",
    "        lrate = 0.0002\n",
    "    if epoch > 150:\n",
    "        lrate = 0.0001\n",
    "    return lrate\n",
    "model20 = load_model('./model20.h5')\n",
    "history20 = model20.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=180,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=160)\n",
    "accuracy20 = model20.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy20[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20.save('./model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model3.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model22 = load_model('./model21.h5')\n",
    "history22 = model22.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=200,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=145)\n",
    "accuracy22 = model22.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy22[1])\n",
    "model22.save('./model22.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model22.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00001\n",
    "    return lrate\n",
    "model23 = load_model('./model22.h5')\n",
    "history23 = model23.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=220,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=200)\n",
    "accuracy23 = model23.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy22[1])\n",
    "model23.save('./model23.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model23.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00001\n",
    "    if epoch > 220:\n",
    "        lrate = 0.0000001\n",
    "    return lrate\n",
    "model24 = load_model('./model23.h5')\n",
    "history24 = model24.fit_generator(datagen.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=225,\\\n",
    "                    verbose=1,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=220)\n",
    "accuracy24 = model24.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy24[1])\n",
    "model24.save('./model24.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model24.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00001\n",
    "    if epoch > 220:\n",
    "        lrate = 0.000001\n",
    "    return lrate\n",
    "model3 = model\n",
    "history3 = model3.fit_generator(datagen2.flow(training_set_norm, training_label_one_hot_encode, batch_size=32),\\\n",
    "                    steps_per_epoch=training_set_norm.shape[0] // 32,epochs=150,\\\n",
    "                    verbose=0,validation_data=(test_data_norm,test_label_one_hot_encoded),callbacks=[LearningRateScheduler(lr_schedule)],initial_epoch=125)\n",
    "accuracy3 = model3.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy3[1])\n",
    "model3.save('./model3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(training_set,axis=(0,1,2,3))\n",
    "std = np.std(training_set,axis=(0,1,2,3))\n",
    "x_train = (training_set-mean)/(std+1e-7)\n",
    "x_test = (test_data-mean)/(std+1e-7)\n",
    "num_classes = 10\n",
    "y_train = training_label_one_hot_encode\n",
    "y_test = test_label_one_hot_encoded\n",
    "\n",
    "baseMapNum = 32\n",
    "weight_decay = 1e-4\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(Dropout(0.4))\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model4.summary()\n",
    "\n",
    "#data augmentation\n",
    "datagen4 = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen4.fit(x_train)\n",
    "\n",
    "#training\n",
    "batch_size = 64\n",
    "epochs=25\n",
    "opt_rms = RMSprop(lr=0.001,decay=1e-6)\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "hitsory41= model4.fit_generator(datagen4.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model4.save_weights('cifar10_normal_rms_ep75.h5')\n",
    "\n",
    "opt_rms = RMSprop(lr=0.0005,decay=1e-6)\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "hitsory42 = model4.fit_generator(datagen4.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model4.save_weights('cifar10_normal_rms_ep100.h5')\n",
    "\n",
    "opt_rms = RMSprop(lr=0.0003,decay=1e-6)\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "hitsory43 = model4.fit_generator(datagen4.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test))\n",
    "model4.save_weights('cifar10_normal_rms_ep125.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.load('/kaggle/input/cs4487cp/test_data/y_test.npy')\n",
    "pp_norm = (pp-mean)/(std+1e-7)\n",
    "test_res = []\n",
    "for i in model4.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "# summarize_diagnostics(history41)\n",
    "# summarize_diagnostics(history42)\n",
    "# summarize_diagnostics(history43)\n",
    "\n",
    "df = pd.DataFrame({'Category':test_res})\n",
    "df['Index'] = df.index\n",
    "df = df[['Index','Category']]\n",
    "df.to_csv('./test_res4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoint\n",
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "\n",
    "'''EfficientNet in PyTorch.\n",
    "Paper: \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\".\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def main(resume,lr,epochAdd):\n",
    "    import torch.nn as nn\n",
    "    class Block(nn.Module):\n",
    "        '''expand + depthwise + pointwise + squeeze-excitation'''\n",
    "\n",
    "        def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "            super(Block, self).__init__()\n",
    "            self.stride = stride\n",
    "\n",
    "            planes = expansion * in_planes\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "            self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                                   stride=stride, padding=1, groups=planes, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "            self.conv3 = nn.Conv2d(\n",
    "                planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "            self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "            self.shortcut = nn.Sequential()\n",
    "            if stride == 1 and in_planes != out_planes:\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_planes, out_planes, kernel_size=1,\n",
    "                              stride=1, padding=0, bias=False),\n",
    "                    nn.BatchNorm2d(out_planes),\n",
    "                )\n",
    "\n",
    "            # SE layers\n",
    "            self.fc1 = nn.Conv2d(out_planes, out_planes//16, kernel_size=1)\n",
    "            self.fc2 = nn.Conv2d(out_planes//16, out_planes, kernel_size=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(self.conv1(x)))\n",
    "            out = F.relu(self.bn2(self.conv2(out)))\n",
    "            out = self.bn3(self.conv3(out))\n",
    "            shortcut = self.shortcut(x) if self.stride == 1 else out\n",
    "            # Squeeze-Excitation\n",
    "            w = F.avg_pool2d(out, out.size(2))\n",
    "            w = F.relu(self.fc1(w))\n",
    "            w = self.fc2(w).sigmoid()\n",
    "            out = out * w + shortcut\n",
    "            return out\n",
    "\n",
    "\n",
    "    class EfficientNet(nn.Module):\n",
    "        def __init__(self, cfg, num_classes=10):\n",
    "            super(EfficientNet, self).__init__()\n",
    "            self.cfg = cfg\n",
    "            self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
    "                                   stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.layers = self._make_layers(in_planes=32)\n",
    "            self.linear = nn.Linear(cfg[-1][1], num_classes)\n",
    "\n",
    "        def _make_layers(self, in_planes):\n",
    "            layers = []\n",
    "            for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "                strides = [stride] + [1]*(num_blocks-1)\n",
    "                for stride in strides:\n",
    "                    layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                    in_planes = out_planes\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(self.conv1(x)))\n",
    "            out = self.layers(out)\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.linear(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "    def EfficientNetB0():\n",
    "        # (expansion, out_planes, num_blocks, stride)\n",
    "        cfg = [(1,  16, 1, 2),\n",
    "               (6,  24, 2, 1),\n",
    "               (6,  40, 2, 2),\n",
    "               (6,  80, 3, 2),\n",
    "               (6, 112, 3, 1),\n",
    "               (6, 192, 4, 2),\n",
    "               (6, 320, 1, 2)]\n",
    "        return EfficientNet(cfg)\n",
    "\n",
    "\n",
    "#     def test():\n",
    "#         net = EfficientNetB0()\n",
    "#         x = torch.randn(2, 3, 32, 32)\n",
    "#         y = net(x)\n",
    "#         print(y.shape)\n",
    "\n",
    "\n",
    "    # test()\n",
    "    import os\n",
    "    import sys\n",
    "    import time\n",
    "    import math\n",
    "\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.init as init\n",
    "    \n",
    "    \n",
    "    def get_mean_and_std(dataset):\n",
    "        '''Compute the mean and std value of dataset.'''\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "        mean = torch.zeros(3)\n",
    "        std = torch.zeros(3)\n",
    "        print('==> Computing mean and std..')\n",
    "        for inputs, targets in dataloader:\n",
    "            for i in range(3):\n",
    "                mean[i] += inputs[:,i,:,:].mean()\n",
    "                std[i] += inputs[:,i,:,:].std()\n",
    "        mean.div_(len(dataset))\n",
    "        std.div_(len(dataset))\n",
    "        return mean, std\n",
    "\n",
    "    def init_params(net):\n",
    "        '''Init layer parameters.'''\n",
    "        for m in net.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal(m.weight, mode='fan_out')\n",
    "                if m.bias:\n",
    "                    init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant(m.weight, 1)\n",
    "                init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal(m.weight, std=1e-3)\n",
    "                if m.bias:\n",
    "                    init.constant(m.bias, 0)\n",
    "\n",
    "    term_width = 100\n",
    "\n",
    "    TOTAL_BAR_LENGTH = 65.\n",
    "    last_time = time.time()\n",
    "    begin_time = last_time\n",
    "    def progress_bar(current, total, msg=None):\n",
    "        global last_time, begin_time\n",
    "        if current == 0:\n",
    "            begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "        cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "        rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "        sys.stdout.write(' [')\n",
    "        for i in range(cur_len):\n",
    "            sys.stdout.write('=')\n",
    "        sys.stdout.write('>')\n",
    "        for i in range(rest_len):\n",
    "            sys.stdout.write('.')\n",
    "        sys.stdout.write(']')\n",
    "\n",
    "        cur_time = time.time()\n",
    "        step_time = cur_time - last_time\n",
    "        last_time = cur_time\n",
    "        tot_time = cur_time - begin_time\n",
    "\n",
    "        L = []\n",
    "        L.append('  Step: %s' % format_time(step_time))\n",
    "        L.append(' | Tot: %s' % format_time(tot_time))\n",
    "        if msg:\n",
    "            L.append(' | ' + msg)\n",
    "\n",
    "        msg = ''.join(L)\n",
    "        sys.stdout.write(msg)\n",
    "        for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "            sys.stdout.write(' ')\n",
    "\n",
    "        # Go back to the center of the bar.\n",
    "        for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "            sys.stdout.write('\\b')\n",
    "        sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "        if current < total-1:\n",
    "            sys.stdout.write('\\r')\n",
    "        else:\n",
    "            sys.stdout.write('\\n')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    def format_time(seconds):\n",
    "        days = int(seconds / 3600/24)\n",
    "        seconds = seconds - days*3600*24\n",
    "        hours = int(seconds / 3600)\n",
    "        seconds = seconds - hours*3600\n",
    "        minutes = int(seconds / 60)\n",
    "        seconds = seconds - minutes*60\n",
    "        secondsf = int(seconds)\n",
    "        seconds = seconds - secondsf\n",
    "        millis = int(seconds*1000)\n",
    "\n",
    "        f = ''\n",
    "        i = 1\n",
    "        if days > 0:\n",
    "            f += str(days) + 'D'\n",
    "            i += 1\n",
    "        if hours > 0 and i <= 2:\n",
    "            f += str(hours) + 'h'\n",
    "            i += 1\n",
    "        if minutes > 0 and i <= 2:\n",
    "            f += str(minutes) + 'm'\n",
    "            i += 1\n",
    "        if secondsf > 0 and i <= 2:\n",
    "            f += str(secondsf) + 's'\n",
    "            i += 1\n",
    "        if millis > 0 and i <= 2:\n",
    "            f += str(millis) + 'ms'\n",
    "            i += 1\n",
    "        if f == '':\n",
    "            f = '0ms'\n",
    "        return f\n",
    "\n",
    "\n",
    "    # parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "    # parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "    # parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "    # args = parser.parse_args()\n",
    "    best_acc = 0  # best test accuracy\n",
    "    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "    # Data\n",
    "    print('==> Preparing data..')\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # Model\n",
    "    print('==> Building model..')\n",
    "    # net = VGG('VGG19')\n",
    "    # net = ResNet18()\n",
    "    # net = PreActResNet18()\n",
    "    # net = GoogLeNet()\n",
    "    # net = DenseNet121()\n",
    "    # net = ResNeXt29_2x64d()\n",
    "    # net = MobileNet()\n",
    "    # net = MobileNetV2()\n",
    "    # net = DPN92()\n",
    "    # net = ShuffleNetG2()\n",
    "    # net = SENet18()\n",
    "    # net = ShuffleNetV2(1)\n",
    "    net = EfficientNetB0()\n",
    "    net = net.to(device)\n",
    "    if device == 'cuda':\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    if resume:\n",
    "        # Load checkpoint.\n",
    "        print('==> Resuming from checkpoint..')\n",
    "        assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "        checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        best_acc = checkpoint['acc']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    # Training\n",
    "    def train(epoch):\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    def test(epoch):\n",
    "        global best_acc\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                    % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        # Save checkpoint.\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_acc:\n",
    "            print('Saving..')\n",
    "            state = {\n",
    "                'net': net.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.pth')\n",
    "            best_acc = acc\n",
    "\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch+epochAdd):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "    return net\n",
    "lrate= [0.1,0.01,0.001]\n",
    "epochAdd=[150,100,100]\n",
    "nettt = []\n",
    "for i in range(3):\n",
    "    nettt.append(main(i!=0,lrate[i],epochAdd[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -O ./data/cifar-10-python.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "pp_torch = transform_test(pp)\n",
    "nettt[len(nettt)-1].eval()\n",
    "with torch.no_grad():\n",
    "    input = pp_torch.to(device)\n",
    "    outputs = nettt[len(nettt)-1](inputs)\n",
    "    _, predicted = outputs.max(1)\n",
    "#     for batch_idx, (inputs, targets) in enumerate(pploader):\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         outputs = nettt[len(nettt)-1](inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "#         test_loss += loss.item()\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         total += targets.size(0)\n",
    "#         correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#         progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "#             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model4.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))\n",
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "summarize_diagnostics(history23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.load('./y_test.npy')\n",
    "pp_norm = normalization(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = []\n",
    "for i in model.predict(pp_norm):\n",
    "    test_res.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(pp,test_res)\n",
    "plotImages(pp[2400:],test_res[2400:])\n",
    "plotImages(pp[2400*2:],test_res[2400*2:])\n",
    "plotImages(pp[2400*3:],test_res[2400*3:])\n",
    "# for i in range(0,100,5):\n",
    "#     plotImages(pp[i:],test_res[i:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('Classification Accuracy')\n",
    "\tpyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "# \tfilename = sys.argv[0].split('/')[-1]\n",
    "# \tpyplot.savefig(filename + '_plot.png')\n",
    "# \tpyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_diagnostics(history20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2 = model2.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "print(\"Accuracy: \",accuracy2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /kaggle/input/cs4487cp/test_data/test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Category':test_res})\n",
    "df['Index'] = df.index\n",
    "df = df[['Index','Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./test_res4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(test_res, open('/kaggle/output/test_res','wb'))\n",
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_norm\n",
    "test_data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [pp[3]]:\n",
    "    for j in training_set:\n",
    "        if (i == j).all():\n",
    "            print('WTF?')\n",
    "    for j in test_data:\n",
    "        if (i == j).all():\n",
    "            print('WTF?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [15]:\n",
    "    for j in range(1):\n",
    "        print('try: '+ str(j))\n",
    "        print('epoch: '+str(i))\n",
    "        model = Sequential([\n",
    "            Conv2D(64, kernel_size=3, activation='relu',input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "            MaxPooling2D((2,2),padding='same'),\n",
    "            Conv2D(128, kernel_size=3, activation='relu'),\n",
    "            MaxPooling2D((2,2),padding='same'),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        history = model.fit(\n",
    "            x=training_set_norm,\n",
    "            y=training_label_one_hot_encode,\n",
    "            epochs=i,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "        )\n",
    "        accuracy = model.evaluate(x=test_data_norm,y=test_label_one_hot_encoded,batch_size=32)\n",
    "        res[(j,i)] = accuracy[1]\n",
    "        print(\"Accuracy: \",accuracy[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [5,10,15,20]:\n",
    "    print('epoch: '+str(i))\n",
    "    for j in range(3):\n",
    "        print('try: '+ str(j))\n",
    "        print('acc: '+ str(res[(j,i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import EfficientNetB0 as Net\n",
    "from efficientnet import center_crop_and_resize, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = Net(weights=\"imagenet\", include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full4, num_outputs=10, activation_fn=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n",
      "WARNING:tensorflow:From <ipython-input-40-b331ba17c6b5>:272: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preprocess_batch_1.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b331ba17c6b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mn_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mload_preprocess_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m                 \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-b331ba17c6b5>\u001b[0m in \u001b[0;36mload_preprocess_training_batch\u001b[1;34m(batch_id, batch_size)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m    131\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'preprocess_batch_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.p'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;31m# Return the training data in batches of size <batch_size> or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preprocess_batch_1.p'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
